"use strict";(globalThis.webpackChunkmy_docusaurus_project=globalThis.webpackChunkmy_docusaurus_project||[]).push([[6422],{636:(e,n,i)=>{i.r(n),i.d(n,{assets:()=>d,contentTitle:()=>c,default:()=>u,frontMatter:()=>l,metadata:()=>o,toc:()=>h});const o=JSON.parse('{"id":"module-4/whisper-voice-integration","title":"4.2 Voice-to-Action: OpenAI Whisper","description":"Giving the Robot Ears","source":"@site/docs/module-4/02-whisper-voice-integration.mdx","sourceDirName":"module-4","slug":"/module-4/whisper-voice-integration","permalink":"/phys-ai-book/docs/module-4/whisper-voice-integration","draft":false,"unlisted":false,"tags":[],"version":"current","sidebarPosition":2,"frontMatter":{},"sidebar":"tutorialSidebar","previous":{"title":"4.1 Vision-Language-Action (VLA) Models","permalink":"/phys-ai-book/docs/module-4/vla-introduction"},"next":{"title":"4.3 Cognitive Planning: From Chat to JSON","permalink":"/phys-ai-book/docs/module-4/llm-cognitive-planning"}}');var s=i(4848),r=i(8453),t=i(3715),a=i(4021);const l={},c="4.2 Voice-to-Action: OpenAI Whisper",d={},h=[{value:"Giving the Robot Ears",id:"giving-the-robot-ears",level:2},{value:"Setting up Whisper",id:"setting-up-whisper",level:3},{value:"Optimized Inference: Whisper on Jetson (Distil-Whisper)",id:"optimized-inference-whisper-on-jetson-distil-whisper",level:2},{value:"Wake Word Detection (Porcupine / OpenWakeWord)",id:"wake-word-detection-porcupine--openwakeword",level:3},{value:"ROS 2 Audio Architecture",id:"ros-2-audio-architecture",level:3},{value:"Robot Ko Kaan Dena: Whisper",id:"robot-ko-kaan-dena-whisper",level:2},{value:"Whisper Setup",id:"whisper-setup",level:3},{value:"Jetson Ke Liye Optimization",id:"jetson-ke-liye-optimization",level:2}];function p(e){const n={code:"code",em:"em",h1:"h1",h2:"h2",h3:"h3",header:"header",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,r.R)(),...e.components};return(0,s.jsxs)(s.Fragment,{children:[(0,s.jsx)(n.header,{children:(0,s.jsx)(n.h1,{id:"42-voice-to-action-openai-whisper",children:"4.2 Voice-to-Action: OpenAI Whisper"})}),"\n",(0,s.jsxs)(t.A,{level:"novice",language:"english",children:[(0,s.jsx)(n.h2,{id:"giving-the-robot-ears",children:"Giving the Robot Ears"}),(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"The Goal"}),"\nWe want to talk to the robot: ",(0,s.jsx)(n.em,{children:'"Robot, go to the kitchen."'}),"\nThe robot needs to convert Sound Waves -> Text.\nThis technology is ",(0,s.jsx)(n.strong,{children:"ASR (Automatic Speech Recognition)"}),".\nThe best open-source model currently is ",(0,s.jsx)(n.strong,{children:"OpenAI Whisper"}),"."]}),(0,s.jsx)(n.h3,{id:"setting-up-whisper",children:"Setting up Whisper"}),(0,s.jsx)(n.p,{children:"We will run Whisper on the PC (or Cloud) because it is heavy."}),(0,s.jsxs)(n.ol,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Install"}),":","\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:"pip install openai-whisper sounddevice numpy\n"})}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsxs)(n.strong,{children:["The Python Script (",(0,s.jsx)(n.code,{children:"voice_commander.py"}),")"]}),":\nThis script listens to the microphone, converts speech to text, and publishes it to a ROS 2 topic ",(0,s.jsx)(n.code,{children:"/voice_command"}),"."]}),"\n"]}),(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:'import rclpy\nfrom rclpy.node import Node\nfrom std_msgs.msg import String\nimport whisper\nimport sounddevice as sd\nimport numpy as np\n\nclass VoiceNode(Node):\n    def __init__(self):\n        super().__init__(\'voice_node\')\n        self.pub = self.create_publisher(String, \'voice_command\', 10)\n        # Load Model (Base is faster, Medium is more accurate)\n        self.model = whisper.load_model("base")\n        self.get_logger().info("Listening...")\n\n    def listen_and_publish(self):\n        # Record 5 seconds of audio\n        audio = sd.rec(int(5 * 16000), samplerate=16000, channels=1)\n        sd.wait()\n        \n        # Transcribe\n        result = self.model.transcribe(audio.flatten())\n        text = result["text"]\n        \n        self.get_logger().info(f"You said: {text}")\n        msg = String()\n        msg.data = text\n        self.pub.publish(msg)\n\n# (Main function omitted)\n'})}),(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Testing:"}),'\nRun the node. Say "Hello Robot".\nOpen a terminal: ',(0,s.jsx)(n.code,{children:"ros2 topic echo /voice_command"}),".\nYou should see: ",(0,s.jsx)(n.code,{children:'data: " Hello Robot."'})]})]}),"\n",(0,s.jsxs)(t.A,{level:"expert",language:"english",children:[(0,s.jsx)(n.h2,{id:"optimized-inference-whisper-on-jetson-distil-whisper",children:"Optimized Inference: Whisper on Jetson (Distil-Whisper)"}),(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"Latency vs. Accuracy"})}),(0,s.jsx)(n.p,{children:'Standard Whisper models are Transformers. The "Large-v3" model is highly accurate but takes ~10GB VRAM and ~2 seconds to transcribe on a GPU.\nFor real-time interaction, 2 seconds is too slow (Human interaction feels laggy after 500ms).'}),(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"Optimization Strategies for Jetson Orin:"})}),(0,s.jsxs)(n.ol,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Distil-Whisper"}),": A distilled version that is 6x faster with < 1% accuracy loss."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Faster-Whisper (CTranslate2)"}),": Uses quantization (INT8) to run efficiently on inference hardware."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"VAD (Voice Activity Detection)"}),": Do not run Whisper on silence. Use a cheap WebRTC-VAD model to detect ",(0,s.jsx)(n.em,{children:"when"})," someone is speaking, then trigger Whisper."]}),"\n"]}),(0,s.jsx)(n.h3,{id:"wake-word-detection-porcupine--openwakeword",children:"Wake Word Detection (Porcupine / OpenWakeWord)"}),(0,s.jsxs)(n.p,{children:["Streaming audio to Whisper 24/7 melts the Jetson.\nWe use a ",(0,s.jsx)(n.strong,{children:"Wake Word"}),' engine (like "Hey Robot").']}),(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:["Architecture: ",(0,s.jsx)(n.code,{children:"Microphone -> VAD -> WakeWord -> Whisper -> LLM"}),"."]}),"\n"]}),(0,s.jsx)(n.h3,{id:"ros-2-audio-architecture",children:"ROS 2 Audio Architecture"}),(0,s.jsxs)(n.p,{children:["Raw audio in ROS 2 is handled by ",(0,s.jsx)(n.code,{children:"audio_common"}),".\nHowever, for Python-centric VLA pipelines, we simply use PyAudio/SoundDevice inside a ROS node."]}),(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"QoS"}),": Use ",(0,s.jsx)(n.code,{children:"Reliable"})," for text commands. Use ",(0,s.jsx)(n.code,{children:"BestEffort"})," if streaming raw audio bytes to a remote server."]}),"\n"]})]}),"\n",(0,s.jsxs)(t.A,{level:"novice",language:"urdu",children:[(0,s.jsx)(n.h2,{id:"robot-ko-kaan-dena-whisper",children:"Robot Ko Kaan Dena: Whisper"}),(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Maqsad"}),"\nHum chahte hain robot se baat karna: ",(0,s.jsx)(n.em,{children:'"Kitchen mein jao."'}),"\nRobot ko Awaaz se Text banana hai.\nIs ke liye hum ",(0,s.jsx)(n.strong,{children:"OpenAI Whisper"})," use karenge."]}),(0,s.jsx)(n.h3,{id:"whisper-setup",children:"Whisper Setup"}),(0,s.jsxs)(n.ol,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Install"}),":","\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:"pip install openai-whisper sounddevice\n"})}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Python Script"}),":\nHum ek node banayenge jo microphone sunta hai, aur text ko ",(0,s.jsx)(n.code,{children:"/voice_command"})," topic par bhejta hai."]}),"\n"]}),(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:'# (Code English section wala same hai)\n# Model load karein\nself.model = whisper.load_model("base")\n\n# Audio record karein\naudio = sd.rec(...)\n# Text banayein\ntext = self.model.transcribe(audio)\n# ROS par bhejein\nself.pub.publish(text)\n'})}),(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Test Karein:"}),'\nNode chalayein aur bolein "Salaam Robot".\nDoosre terminal mein dekhein: ',(0,s.jsx)(n.code,{children:"ros2 topic echo /voice_command"}),".\nAap ko nazar aayega: ",(0,s.jsx)(n.code,{children:'data: "Salaam Robot."'})]})]}),"\n",(0,s.jsxs)(t.A,{level:"expert",language:"urdu",children:[(0,s.jsx)(n.h2,{id:"jetson-ke-liye-optimization",children:"Jetson Ke Liye Optimization"}),(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"Speed aur Accuracy"})}),(0,s.jsx)(n.p,{children:"Whisper ka bara model bohat slow hai. Agar robot 2 second baad jawab de, to maza nahi aata.\nJetson ke liye humein tez tareeqa chahiye."}),(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Distil-Whisper"}),"\nYe chota version hai jo 6 guna tez chalta hai."]}),(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Wake Word (Jaagnay Ka Lafz)"}),'\nAgar hum har waqt Whisper chalayenge to Jetson garam ho jaye ga.\nHum "Wake Word" use karte hain (jaise "Hey Siri").\nPehle sasta model sunta hai "Hey Robot". Jab wo sun leta hai, tab Whisper on hota hai.']}),(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Architecture"}),":\n",(0,s.jsx)(n.code,{children:"Mic -> Shor Check (VAD) -> Wake Word -> Whisper -> Dimagh"}),"."]})]}),"\n",(0,s.jsx)(a.A,{questions:[{question:"What is the primary function of OpenAI Whisper?",options:["Text-to-Speech","Automatic Speech Recognition (Audio-to-Text)","Image Generation","Robot Walking"],correctAnswer:1},{question:"Why do we use 'Voice Activity Detection' (VAD) before running Whisper?",options:["To save battery and compute by only processing when someone is actually talking","To make the audio louder","To translate the language","It is required by ROS"],correctAnswer:0},{question:"Urdu: Wake Word (jaise 'Hey Robot') ka faida kya hai?",options:["Robot ko neend aati hai","Taake bhaari AI model har waqt na chalta rahe","Awaz saaf hoti hai","Robot khush hota hai"],correctAnswer:1}]})]})}function u(e={}){const{wrapper:n}={...(0,r.R)(),...e.components};return n?(0,s.jsx)(n,{...e,children:(0,s.jsx)(p,{...e})}):p(e)}}}]);