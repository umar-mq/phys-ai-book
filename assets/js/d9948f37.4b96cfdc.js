"use strict";(globalThis.webpackChunkmy_docusaurus_project=globalThis.webpackChunkmy_docusaurus_project||[]).push([[2173],{4569:(e,n,a)=>{a.r(n),a.d(n,{assets:()=>d,contentTitle:()=>h,default:()=>u,frontMatter:()=>l,metadata:()=>s,toc:()=>c});const s=JSON.parse('{"id":"module-4/vla-introduction","title":"4.1 Vision-Language-Action (VLA) Models","description":"When Robots Understand English","source":"@site/docs/module-4/01-vla-introduction.mdx","sourceDirName":"module-4","slug":"/module-4/vla-introduction","permalink":"/phys-ai-book/docs/module-4/vla-introduction","draft":false,"unlisted":false,"tags":[],"version":"current","sidebarPosition":1,"frontMatter":{},"sidebar":"tutorialSidebar","previous":{"title":"3.7 The Brain that Learns: Reinforcement Learning (RL)","permalink":"/phys-ai-book/docs/module-3/reinforcement-learning-basics"},"next":{"title":"4.2 Voice-to-Action: OpenAI Whisper","permalink":"/phys-ai-book/docs/module-4/whisper-voice-integration"}}');var i=a(4848),o=a(8453),r=a(3715),t=a(4021);const l={},h="4.1 Vision-Language-Action (VLA) Models",d={},c=[{value:"When Robots Understand English",id:"when-robots-understand-english",level:2},{value:"How it Works (RT-2 / Prism)",id:"how-it-works-rt-2--prism",level:3},{value:"Foundation Models for Embodied AI",id:"foundation-models-for-embodied-ai",level:2},{value:"The Modular Approach (VLM + Planner)",id:"the-modular-approach-vlm--planner",level:3},{value:"Jab Robot Baat Samajhne Lagay: VLA Models",id:"jab-robot-baat-samajhne-lagay-vla-models",level:2},{value:"Kaise Kaam Karta Hai?",id:"kaise-kaam-karta-hai",level:3},{value:"Foundation Models aur Embodied AI",id:"foundation-models-aur-embodied-ai",level:2},{value:"Modular Pipeline (Jetson Friendly)",id:"modular-pipeline-jetson-friendly",level:3}];function m(e){const n={annotation:"annotation",code:"code",em:"em",h1:"h1",h2:"h2",h3:"h3",header:"header",li:"li",math:"math",mi:"mi",mo:"mo",mrow:"mrow",ol:"ol",p:"p",semantics:"semantics",span:"span",strong:"strong",ul:"ul",...(0,o.R)(),...e.components};return(0,i.jsxs)(i.Fragment,{children:[(0,i.jsx)(n.header,{children:(0,i.jsx)(n.h1,{id:"41-vision-language-action-vla-models",children:"4.1 Vision-Language-Action (VLA) Models"})}),"\n",(0,i.jsxs)(r.A,{level:"novice",language:"english",children:[(0,i.jsx)(n.h2,{id:"when-robots-understand-english",children:"When Robots Understand English"}),(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"The Old Way"}),"\nIf you wanted a robot to pick up a red cup, you wrote code:\n",(0,i.jsx)(n.code,{children:"if (object.color == red && object.type == cup) { pick(object); }"}),'\nThis is rigid. If you ask "Pick up the thing that holds water", the robot fails.']}),(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"The New Way: VLA"}),"\n",(0,i.jsx)(n.strong,{children:"Vision-Language-Action"})," models connect ChatGPT-like brains to robot bodies.\nYou can say: ",(0,i.jsx)(n.em,{children:'"I am thirsty."'}),"\nThe Robot thinks:"]}),(0,i.jsxs)(n.ol,{children:["\n",(0,i.jsx)(n.li,{children:'"Thirsty" -> I need water.'}),"\n",(0,i.jsx)(n.li,{children:'"Water" -> Is usually in a cup or bottle.'}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Vision"}),": Look for a cup."]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Action"}),": Navigate to cup, Pick up cup, Bring to human."]}),"\n"]}),(0,i.jsxs)(n.p,{children:["This is the convergence of ",(0,i.jsx)(n.strong,{children:"LLMs"})," (Large Language Models) and ",(0,i.jsx)(n.strong,{children:"Robotics"}),"."]}),(0,i.jsx)(n.h3,{id:"how-it-works-rt-2--prism",children:"How it Works (RT-2 / Prism)"}),(0,i.jsx)(n.p,{children:"These models take three inputs:"}),(0,i.jsxs)(n.ol,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Image"}),": What the robot sees."]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Text"}),": What the human said."]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Robot State"}),": Where the arm is now."]}),"\n"]}),(0,i.jsx)(n.p,{children:"And output:"}),(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Action Tokens"}),": Numbers that control the motors (x, y, z, gripper)."]}),"\n"]}),(0,i.jsxs)(n.p,{children:["In this module, we won't build a VLA from scratch (requires Google-level compute). We will use ",(0,i.jsx)(n.strong,{children:"OpenAI/LLaMA"}),' for the reasoning ("I need water") and connect it to ',(0,i.jsx)(n.strong,{children:"ROS 2 actions"})," for the movement."]})]}),"\n",(0,i.jsxs)(r.A,{level:"expert",language:"english",children:[(0,i.jsx)(n.h2,{id:"foundation-models-for-embodied-ai",children:"Foundation Models for Embodied AI"}),(0,i.jsx)(n.p,{children:(0,i.jsx)(n.strong,{children:"From LLMs to VLAs"})}),(0,i.jsxs)(n.p,{children:["Large Language Models (LLMs) like GPT-4 process text.\nVision-Language Models (VLMs) like CLIP process text and images.\n",(0,i.jsx)(n.strong,{children:"VLA (Vision-Language-Action)"})," models like Google's RT-2 or Stanford's Octo process text+images and output ",(0,i.jsx)(n.strong,{children:"Control Actions"}),"."]}),(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Tokenization of Action Space"}),"\nHow does a Transformer output motor commands?\nWe discretize the action space."]}),(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsxs)(n.span,{className:"katex",children:[(0,i.jsx)(n.span,{className:"katex-mathml",children:(0,i.jsx)(n.math,{xmlns:"http://www.w3.org/1998/Math/MathML",children:(0,i.jsxs)(n.semantics,{children:[(0,i.jsxs)(n.mrow,{children:[(0,i.jsx)(n.mi,{children:"x"}),(0,i.jsx)(n.mo,{separator:"true",children:","}),(0,i.jsx)(n.mi,{children:"y"}),(0,i.jsx)(n.mo,{separator:"true",children:","}),(0,i.jsx)(n.mi,{children:"z"})]}),(0,i.jsx)(n.annotation,{encoding:"application/x-tex",children:"x, y, z"})]})})}),(0,i.jsx)(n.span,{className:"katex-html","aria-hidden":"true",children:(0,i.jsxs)(n.span,{className:"base",children:[(0,i.jsx)(n.span,{className:"strut",style:{height:"0.625em",verticalAlign:"-0.1944em"}}),(0,i.jsx)(n.span,{className:"mord mathnormal",children:"x"}),(0,i.jsx)(n.span,{className:"mpunct",children:","}),(0,i.jsx)(n.span,{className:"mspace",style:{marginRight:"0.1667em"}}),(0,i.jsx)(n.span,{className:"mord mathnormal",style:{marginRight:"0.03588em"},children:"y"}),(0,i.jsx)(n.span,{className:"mpunct",children:","}),(0,i.jsx)(n.span,{className:"mspace",style:{marginRight:"0.1667em"}}),(0,i.jsx)(n.span,{className:"mord mathnormal",style:{marginRight:"0.04398em"},children:"z"})]})})]})," coordinates are mapped to tokens between 0-255."]}),"\n",(0,i.jsxs)(n.li,{children:["The model predicts: ",(0,i.jsx)(n.code,{children:"[Move_Arm, 120, 45, 200, Open_Gripper]"}),"."]}),"\n",(0,i.jsx)(n.li,{children:"These tokens are de-tokenized into continuous velocity commands for the robot controller."}),"\n"]}),(0,i.jsx)(n.h3,{id:"the-modular-approach-vlm--planner",children:"The Modular Approach (VLM + Planner)"}),(0,i.jsx)(n.p,{children:"Since end-to-end VLAs are heavy to run on edge (Jetson), we often use a modular pipeline in this course:"}),(0,i.jsxs)(n.ol,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"VLM (e.g., LLaVA / NanoLLaVA)"}),': Scene Description. "There is a red apple on the table."']}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"LLM (e.g., Llama-3-8B)"}),': Planner. Input: "User wants fruit". Output: ',(0,i.jsx)(n.code,{children:'[pick_object("apple"), bring_to("user")]'}),"."]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"ROS 2 Action Server"}),": Executes ",(0,i.jsx)(n.code,{children:"pick_object"})," using MoveIt / Nav2."]}),"\n"]}),(0,i.jsx)(n.p,{children:'This decouples the "Reasoning" (Heavy, slow) from the "Reflexes" (Fast, safety-critical).'})]}),"\n",(0,i.jsxs)(r.A,{level:"novice",language:"urdu",children:[(0,i.jsx)(n.h2,{id:"jab-robot-baat-samajhne-lagay-vla-models",children:"Jab Robot Baat Samajhne Lagay: VLA Models"}),(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Purana Tareeqa"}),'\nAgar aap robot ko kehte "Laal cup uthao", to aap ko code likhna parta tha.\nAgar aap kehte "Wo cheez uthao jis mein paani peetay hain", to robot fail ho jata.']}),(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Naya Tareeqa: VLA"}),"\n",(0,i.jsx)(n.strong,{children:"Vision-Language-Action"}),".\nAap kehte hain: ",(0,i.jsx)(n.em,{children:'"Mujhe pyaas lagi hai."'}),"\nRobot sochta hai:"]}),(0,i.jsxs)(n.ol,{children:["\n",(0,i.jsx)(n.li,{children:'"Pyaas" -> Paani chahiye.'}),"\n",(0,i.jsx)(n.li,{children:'"Paani" -> Cup ya Bottle mein hota hai.'}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Dekhna"}),": Cup kahan hai?"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Kaam"}),": Cup utha kar laao."]}),"\n"]}),(0,i.jsxs)(n.p,{children:["Yeh ",(0,i.jsx)(n.strong,{children:"ChatGPT"})," aur ",(0,i.jsx)(n.strong,{children:"Robots"})," ka milap hai."]}),(0,i.jsx)(n.h3,{id:"kaise-kaam-karta-hai",children:"Kaise Kaam Karta Hai?"}),(0,i.jsx)(n.p,{children:"Yeh models 3 cheezain input lete hain:"}),(0,i.jsxs)(n.ol,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Tasveer"}),": Robot kya dekh raha hai."]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Text"}),": Insaan ne kya kaha."]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Haalat"}),": Robot ka haath kahan hai."]}),"\n"]}),(0,i.jsx)(n.p,{children:"Aur output dete hain:"}),(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Action"}),": Motors ko kahan hilana hai."]}),"\n"]}),(0,i.jsxs)(n.p,{children:["Hum is course mein ",(0,i.jsx)(n.strong,{children:"Modular Approach"}),' use karenge:\nDimagh (LLM) faisla karega ("Cup uthao"), aur Jism (ROS 2) wo kaam karega.']})]}),"\n",(0,i.jsxs)(r.A,{level:"expert",language:"urdu",children:[(0,i.jsx)(n.h2,{id:"foundation-models-aur-embodied-ai",children:"Foundation Models aur Embodied AI"}),(0,i.jsx)(n.p,{children:(0,i.jsx)(n.strong,{children:"LLMs se VLAs Tak"})}),(0,i.jsxs)(n.p,{children:["LLMs (jaise GPT) sirf text samajhte hain.\nVLA models (jaise RT-2) text, tasveer aur ",(0,i.jsx)(n.strong,{children:"Action"})," samajhte hain."]}),(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Action Tokenization"}),"\nTransformer model motors kaise chalata hai?\nHum motor ki movement ko numbers (Tokens) mein badal dete hain.\nModel kehta hai: ",(0,i.jsx)(n.code,{children:"[Move, 120, 45, 200]"}),".\nHum in numbers ko wapis electrical signals mein badal kar motors ko bhejte hain."]}),(0,i.jsx)(n.h3,{id:"modular-pipeline-jetson-friendly",children:"Modular Pipeline (Jetson Friendly)"}),(0,i.jsx)(n.p,{children:"Kyunke VLA models bohat bhari hotay hain, hum unhein Jetson par nahi chala sakte. Hum tukron mein kaam karte hain:"}),(0,i.jsxs)(n.ol,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"VLM (NanoLLaVA)"}),': Dekhta hai. "Table par seb hai."']}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"LLM (Llama-3)"}),': Sochta hai. "User ko phal chahiye -> Seb uthao."']}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"ROS 2"}),": Karta hai. MoveIt use kar ke haath hilata hai."]}),"\n"]}),(0,i.jsx)(n.p,{children:'Is ka faida ye hai ke "Sochne" wala hissa slow ho sakta hai, magar "Karne" wala hissa (Safety) fast rehta hai.'})]}),"\n",(0,i.jsx)(t.A,{questions:[{question:"What does VLA stand for?",options:["Very Large Array","Vision Language Action","Virtual Local Area","Visual Learning Algorithm"],correctAnswer:1},{question:"In the modular approach, what is the role of the LLM?",options:["To detect edges in the image","To control the motor voltage directly","To act as a Planner (Reasoning about tasks)","To save the file"],correctAnswer:2},{question:"Urdu: VLA model ka input kya hota hai?",options:["Sirf Text","Sirf Image","Image, Text, aur Robot State","Sirf Audio"],correctAnswer:2}]})]})}function u(e={}){const{wrapper:n}={...(0,o.R)(),...e.components};return n?(0,i.jsx)(n,{...e,children:(0,i.jsx)(m,{...e})}):m(e)}}}]);